{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:33:50.513303Z","iopub.execute_input":"2024-12-06T05:33:50.513792Z","iopub.status.idle":"2024-12-06T05:33:50.520892Z","shell.execute_reply.started":"2024-12-06T05:33:50.513738Z","shell.execute_reply":"2024-12-06T05:33:50.519630Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 1: Importing Libraries","metadata":{}},{"cell_type":"code","source":" # Common Libraries\n import numpy as np\n import cv2\n from matplotlib import pyplot as plt\n\n #ML Libraries\n\n #DL Libraries\n import tensorflow as tf\n from tensorflow import keras\n from tensorflow.keras.utils import to_categorical\n from tensorflow.keras.models import Sequential\n from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n from tensorflow.keras.preprocessing.image import ImageDataGenerator\n from tensorflow.keras.datasets import cifar100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:33:50.522906Z","iopub.execute_input":"2024-12-06T05:33:50.523289Z","iopub.status.idle":"2024-12-06T05:33:50.540177Z","shell.execute_reply.started":"2024-12-06T05:33:50.523257Z","shell.execute_reply":"2024-12-06T05:33:50.539087Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 2: Load the Dataset / Read The DataSet","metadata":{}},{"cell_type":"code","source":"# load the sata set and split it between train and test sets\n(x_train, y_train),(x_test, y_test) = cifar100.load_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:33:50.541552Z","iopub.execute_input":"2024-12-06T05:33:50.541948Z","iopub.status.idle":"2024-12-06T05:33:51.447275Z","shell.execute_reply.started":"2024-12-06T05:33:50.541911Z","shell.execute_reply":"2024-12-06T05:33:51.445887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(x_train), x_train.shape, y_train.shape, x_train.ndim, x_train.dtype ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:33:51.449415Z","iopub.execute_input":"2024-12-06T05:33:51.449816Z","iopub.status.idle":"2024-12-06T05:33:51.458361Z","shell.execute_reply.started":"2024-12-06T05:33:51.449744Z","shell.execute_reply":"2024-12-06T05:33:51.457116Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 3: Data Processing / Data Preperation","metadata":{}},{"cell_type":"code","source":"# Scale images to the [0, 1] range\nx_train = x_train.astype(\"float32\") / 255\nx_test = x_test.astype(\"float32\") / 255\n# Make sure images have shape (32, 32, 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:33:51.459668Z","iopub.execute_input":"2024-12-06T05:33:51.460021Z","iopub.status.idle":"2024-12-06T05:33:51.760961Z","shell.execute_reply.started":"2024-12-06T05:33:51.459991Z","shell.execute_reply":"2024-12-06T05:33:51.759732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"x_train shape:\", x_train.shape)\nprint(x_train.shape[0], \"train samples\")\nprint(x_test.shape[0], \"test samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:33:51.762572Z","iopub.execute_input":"2024-12-06T05:33:51.763046Z","iopub.status.idle":"2024-12-06T05:33:51.769359Z","shell.execute_reply.started":"2024-12-06T05:33:51.762998Z","shell.execute_reply":"2024-12-06T05:33:51.768290Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes = 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:33:51.770788Z","iopub.execute_input":"2024-12-06T05:33:51.771219Z","iopub.status.idle":"2024-12-06T05:33:51.782849Z","shell.execute_reply.started":"2024-12-06T05:33:51.771172Z","shell.execute_reply":"2024-12-06T05:33:51.781582Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# convert class vectors to binary class matrics\ny_train = keras.utils.to_categorical(y_train,\n                                     num_classes)\ny_test = keras.utils.to_categorical(y_test,\n                                    num_classes)\ny_test.shape, y_train.shape # Sparse Label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:33:51.784625Z","iopub.execute_input":"2024-12-06T05:33:51.785096Z","iopub.status.idle":"2024-12-06T05:33:51.831728Z","shell.execute_reply.started":"2024-12-06T05:33:51.785050Z","shell.execute_reply":"2024-12-06T05:33:51.830638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# reshape dataset to have a single channel\ntrainX=x_train.reshape((x_train.shape[0], 32, 32, 3))\ntestX=x_test.reshape((x_test.shape[0], 32, 32, 3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:33:51.834234Z","iopub.execute_input":"2024-12-06T05:33:51.834610Z","iopub.status.idle":"2024-12-06T05:33:51.840557Z","shell.execute_reply.started":"2024-12-06T05:33:51.834575Z","shell.execute_reply":"2024-12-06T05:33:51.839257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train,X_test =  trainX,testX","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:33:51.841914Z","iopub.execute_input":"2024-12-06T05:33:51.842301Z","iopub.status.idle":"2024-12-06T05:33:51.859148Z","shell.execute_reply.started":"2024-12-06T05:33:51.842267Z","shell.execute_reply":"2024-12-06T05:33:51.857921Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 4:Build the model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import BatchNormalization","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:33:51.860555Z","iopub.execute_input":"2024-12-06T05:33:51.860930Z","iopub.status.idle":"2024-12-06T05:33:51.873052Z","shell.execute_reply.started":"2024-12-06T05:33:51.860897Z","shell.execute_reply":"2024-12-06T05:33:51.871853Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\nmodel = keras.Sequential()\n# Depthwise\nmodel.add(DepthwiseConv2D(kernel_size=3,\n                          activation=\"relu\", padding =\"same\",  input_shape=(32,32,3)))\n#Pointwise\nmodel.add(Conv2D(32,kernel_size=(1, 1),\n                      activation=\"relu\", padding =\"same\"))\n# 3X1 --> Intermediate Output --> 1X3 --> Final Output\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv2D(kernel_size=3,\n                      activation=\"relu\",padding =\"same\"))\nmodel.add(Conv2D(32,kernel_size=(1, 1),\n                      activation=\"relu\", padding =\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(DepthwiseConv2D(kernel_size=3,\n                      activation=\"relu\", padding =\"same\"))\nmodel.add(Conv2D(64,kernel_size=(1, 1),\n                      activation=\"relu\", padding =\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv2D(kernel_size=3,\n                      activation=\"relu\",padding =\"same\"))\nmodel.add(Conv2D(64,kernel_size=(1, 1),\n                      activation=\"relu\", padding =\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(DepthwiseConv2D(kernel_size=3,\n                      activation=\"relu\", padding =\"same\"))\nmodel.add(Conv2D(128,kernel_size=(1, 1),\n                      activation=\"relu\", padding =\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv2D(kernel_size=3,\n                      activation=\"relu\",padding =\"same\"))\nmodel.add(Conv2D(128,kernel_size=(1, 1),\n                      activation=\"relu\", padding =\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(DepthwiseConv2D(kernel_size=3,\n                      activation=\"relu\", padding =\"same\"))\nmodel.add(Conv2D(256,kernel_size=(1, 1),\n                      activation=\"relu\", padding =\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv2D(kernel_size=3,\n                      activation=\"relu\",padding =\"same\"))\nmodel.add(Conv2D(256,kernel_size=(1, 1),\n                      activation=\"relu\", padding =\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(1024,activation=\"relu\" ))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(512,activation=\"relu\" ))  \nmodel.add(Dropout(0.25))\nmodel.add(Dense(num_classes, activation=\"softmax\")) \nmodel.summary() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:33:51.874393Z","iopub.execute_input":"2024-12-06T05:33:51.874813Z","iopub.status.idle":"2024-12-06T05:33:52.504890Z","shell.execute_reply.started":"2024-12-06T05:33:51.874740Z","shell.execute_reply":"2024-12-06T05:33:52.503813Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adagrad\nopt = Adagrad(learning_rate=0.001,weight_decay=0.002, ema_momentum=0.9)\nmodel.compile(optimizer=opt,\nloss='categorical_crossentropy',\n               metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:33:52.506166Z","iopub.execute_input":"2024-12-06T05:33:52.506579Z","iopub.status.idle":"2024-12-06T05:33:52.516900Z","shell.execute_reply.started":"2024-12-06T05:33:52.506534Z","shell.execute_reply":"2024-12-06T05:33:52.515723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 128\nepochs = 5\nhistory = model.fit(X_train, y_train,\n  batch_size=batch_size,\n  epochs=epochs,\n  verbose=1,\n  validation_data=(X_test, y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:33:52.518248Z","iopub.execute_input":"2024-12-06T05:33:52.518588Z","iopub.status.idle":"2024-12-06T05:45:21.629661Z","shell.execute_reply.started":"2024-12-06T05:33:52.518556Z","shell.execute_reply":"2024-12-06T05:45:21.628361Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# evaluate the model\n_, acc = model.evaluate(X_test, y_test, verbose=0)\nprint('> %.3f' % (acc * 100.0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:47:33.535224Z","iopub.execute_input":"2024-12-06T05:47:33.536370Z","iopub.status.idle":"2024-12-06T05:47:41.396933Z","shell.execute_reply.started":"2024-12-06T05:47:33.536325Z","shell.execute_reply":"2024-12-06T05:47:41.395772Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scores, histories = list(), list()\n# stores scores\nscores.append(acc)\nhistories.append(history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:47:41.398628Z","iopub.execute_input":"2024-12-06T05:47:41.399174Z","iopub.status.idle":"2024-12-06T05:47:41.405111Z","shell.execute_reply.started":"2024-12-06T05:47:41.399119Z","shell.execute_reply":"2024-12-06T05:47:41.403945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print summary\nprint('Accuracy: mean=%.3f std=%.3f, n=%d'\n      % (np.mean(scores)*100,\n      np.std(scores)*100, len(scores)))\n# box and whisker plots of results\nplt.boxplot(scores)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:47:41.620708Z","iopub.execute_input":"2024-12-06T05:47:41.621123Z","iopub.status.idle":"2024-12-06T05:47:41.759211Z","shell.execute_reply.started":"2024-12-06T05:47:41.621089Z","shell.execute_reply":"2024-12-06T05:47:41.758058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(len(histories)):\n# plot loss\n plt.subplot(2, 1, 1)\n plt.title('Cross Entropy Loss')\n plt.plot(histories[i].history['loss'],\n          color='blue', label='train')\n plt.plot(histories[i].history['val_loss'],\n          color='orange', label='test')\n# plot accuracy\n plt.subplot(2, 1, 2)\n plt.title('Classification Accuracy')\n plt.plot(histories[i].history['accuracy'],\n          color='blue', label='train')\n plt.plot(histories[i].history['val_accuracy'],\n          color='orange', label='test')\n plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T05:47:42.101518Z","iopub.execute_input":"2024-12-06T05:47:42.101888Z","iopub.status.idle":"2024-12-06T05:47:42.436776Z","shell.execute_reply.started":"2024-12-06T05:47:42.101855Z","shell.execute_reply":"2024-12-06T05:47:42.435561Z"}},"outputs":[],"execution_count":null}]}